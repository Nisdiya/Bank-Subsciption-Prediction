üìå TL;DR

Built a Bank Subscription Prediction model using classification algorithms on an imbalanced dataset.

Applied SMOTE to balance classes and improve recall.

Compared Logistic Regression, Decision Trees, and Random Forests.

Optimized decision threshold to maximize recall (catch all fraud/positives).

Final model achieved X% accuracy, Y% recall (critical metric).

BANK SUBSCRIPTION PREDICTION
Machine Learning project on Titanic dataset (Kaggle). Includes EDA, preprocessing, Logistic Regression, Decision Tree, Random Forest, and XGBoost models, using SMOTE analysis and roc and auc curve.

BANKING SUBSCRIPTION PREDICTION
This project is based on the famous Banking dataset from Kaggle.
Goal: Predict subscription made by customers using ML models. This was my second ML project where i learned about terms like Oversampling(reduced by SMOTE), Confusion Matrix, Precision, Recall, Threshold and a lot more.

üîπSteps Covered
Data Cleaning & Preprocessing
Exploratory Data Analysis (EDA)
Feature Engineering
Model Building:
Logistic Regression
Decision Tree Classifier
Random Forest (tuned)
XGBoost(tuned)
Using models again, after using SMOTE.
Visualization using Precision Recall Curve.
Performance evaluation

üìä Results
Best Model: Random Forest (manual tuning)
Test Accuracy: 0.901190
Test and Train accuracy gap: 0.0003

üõ†Ô∏è Tools Used
Python, Pandas, NumPy
Matplotlib, Seaborn
Scikit-learn, imbalanced-learn
XGBoost, SMOTE

üìñ Learnings
Understood the concepts of precision, recall and threshold.
Learned how imbalanced data and data balanced using SMOTE, affects model's results.
Explored hyperparameter tuning (max_depth, learning_rate, n_estimators, etc.).
Gained experience by using new visualization graphs.
Learned error solving by own

Model Results üéØ
Random Forest (tuned) performed the best with a small train-test gap.
https://github.com/Nisdiya/Bank-Subsciption-Prediction/tree/main/images
